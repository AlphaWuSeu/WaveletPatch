# WaveletPatch
This is the code for Spatial-enhanced Multi-level Wavelet Patching in Vision Transformers

Our paper is proposing a Spatial-enhanced Multi-level Wavelet Patching module to replace the spatial domain patching in ViT Variants, so we will make direct improvements in the original code of several different networks, which can be seen:

# ViT
The foundational code for our ViT varient is derived from the repository "vision-transformer-pytorch" by ssuncheol. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP ViT.

To learn more about the original "vision-transformer-pytorch" repository by hysts(https://github.com/ssuncheol), please visit here(https://github.com/ssuncheol/vision-transformer-pytorch).

# T2T-ViT
The foundational code for our SMWP T2T-ViT is derived from the repository "T2T-ViT" by yuanli2333. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP T2T-ViT.

To learn more about the original "T2T-ViT" repository by yuanli2333(https://github.com/yuanli2333), please visit here(https://github.com/yitu-opensource/T2T-ViT).

# TNT
The foundational code for our SMWP TNT is derived from the repository "Transformer in Transformer (TNT) and PyramidTNT" by huawei-noah. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP TNT.

To learn more about the original "Transformer in Transformer (TNT) and PyramidTNT" repository by huawei-noah(https://github.com/huawei-noah), please visit here(https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tnt_pytorch).

# Pyramid TNT
The foundational code for our SMWP Pyramid-TNT is derived from the repository "Transformer in Transformer (TNT) and PyramidTNT" by huawei-noah. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP Pyramid-TNT.

To learn more about the original "Transformer in Transformer (TNT) and PyramidTNT" repository by huawei-noah(https://github.com/huawei-noah), please visit here(https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tnt_pytorch).

# Swin
The foundational code for our SMWP Swin is derived from the repository "Swin Transformer for Image Classification
" by Microsoft. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP Swin.

To learn more about the original "Swin Transformer for Image Classification" repository by Microsoft(https://github.com/microsoft), please visit here(https://github.com/microsoft/Swin-Transformer).

# Wave ViT
The foundational code for our SMWP Wave ViT is derived from the repository "ImageNetModel" by YehLi. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP Wave ViT.

To learn more about the original "ImageNetModel" repository by YehLi(https://github.com/YehLi), please visit here(https://github.com/YehLi/ImageNetModel/tree/main).

# Dual ViT
The foundational code for our SMWP Dual ViT is derived from the repository "ImageNetModel" by YehLi. We appreciate their contribution to the open-source community. Our adaptation involves the integration of our own WaveletPatch unit, resulting in the creation of the SMWP Dual ViT.

To learn more about the original "ImageNetModel" repository by YehLi(https://github.com/YehLi), please visit here(https://github.com/YehLi/ImageNetModel/tree/main).

# Dataset ImageNet100
ImageNet-100 is a subset of ImageNet-1k Dataset from ImageNet Large Scale Visual Recognition Challenge 2012. It contains random 100 classes as specified in Labels.json file. The datase can be downloaded in https://www.kaggle.com/datasets/ambityga/imagenet100


